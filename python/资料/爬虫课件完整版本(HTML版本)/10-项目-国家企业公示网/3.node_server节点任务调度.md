## node_server节点任务调度实现
##### 学习目标：
1. 了解 节点任务调度模块的功能和实现

_________________


### 1. node_server节点任务调度的功能

- 轮询gsxt_token队列，取出token
- 根据token从gsxt_task:token中读取任务信息
- 启动爬虫并传递参数

### 2. node_server代码实现

> /gsxt/crawler.py

```
import time
import redis
import random
import requests
from PIL import Image # pip install pillow
from selenium import webdriver
from selenium.webdriver.common.action_chains import ActionChains

from static import (
    GSXT_TOKEN, # redis:list
    GSXT_TASK_TOPIC, # redis:hashmap
)

redis = redis.StrictRedis(decode_responses=True) # 多进程情况下需改为进程中的实例


class CrawlerServer():
    """任务接收并处理"""
    def crawl(self):
        """此处可以改为多任务并行"""
        while True:
            token = redis.lpop(GSXT_TOKEN)
            if token is not None:
                task_dict = redis.hgetall('{}:{}'.format(GSXT_TASK_TOPIC, token))
                print(task_dict)
                # input('用代理ip了吗?免费(推荐西刺代理,只能浏览器用)的比收费的好使!思考下为啥?继续吗?')
                # 调用爬虫
                spider = GsxtJSCrawler(task_dict)
                spider.run()
            print('等待任务中...')
            time.sleep(5)

......
```

### 3. node_server可拓展功能

#### 3.1 负载均衡 
> 通过`psutil os sys`等模块以及`shell`命令获取本节点的状态，根据设定的阈值（cpu、带宽、内存等）来决定是否抢夺redis中gsxt_token中的任务token

#### 3.2 服务注册与节点心跳
> 启动后向消息总线redis中实时注册节点的状态并发送心跳时间戳，用以检测节点的负载以及是否可用

#### 3.3 开启多任务执行crawler爬虫
> 以多进程的方式分别执行不同的token任务

_________________

## 小结
了解 节点任务调度模块的功能和实现