<!DOCTYPE HTML>
<html lang="en" >
    
    <head>
        
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <title>scrapy中间件的使用 | 爬虫课程概要</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 2.6.7">
        
        
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">
        
    <link rel="stylesheet" href="../gitbook/style.css">
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-highlight/website.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-search/search.css">
        
    
        
        <link rel="stylesheet" href="../gitbook/plugins/gitbook-plugin-fontsettings/website.css">
        
    
    

        
    
    
    <link rel="next" href="../07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html" />
    
    
    <link rel="prev" href="../07-scrapy爬虫框架/14.crawlspider类的使用.html" />
    

        
    </head>
    <body>
        
        
    <div class="book"
        data-level="7.7"
        data-chapter-title="scrapy中间件的使用"
        data-filepath="07-scrapy爬虫框架/6.scrapy中间件的使用.md"
        data-basepath=".."
        data-revision="Sat Dec 14 2019 17:07:26 GMT+0800 (中国标准时间)"
        data-innerlanguage="">
    

<div class="book-summary">
    <nav role="navigation">
        <ul class="summary">
            
            
            
            

            

            
    
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../index.html">
                
                        <i class="fa fa-check"></i>
                        
                        Introduction
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1" data-path="01-爬虫基础/index.html">
            
                
                    <a href="../01-爬虫基础/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                        爬虫基础
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1" data-path="01-爬虫基础/1.爬虫概述.html">
            
                
                    <a href="../01-爬虫基础/1.爬虫概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                        爬虫概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="01-爬虫基础/2.http协议复习.html">
            
                
                    <a href="../01-爬虫基础/2.http协议复习.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                        http协议复习
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="2" data-path="02-requests模块/index.html">
            
                
                    <a href="../02-requests模块/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.</b>
                        
                        requests模块
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="2.1" data-path="02-requests模块/requests模块.html">
            
                
                    <a href="../02-requests模块/requests模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>2.1.</b>
                        
                        requests模块
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="3" data-path="03-数据提取/index.html">
            
                
                    <a href="../03-数据提取/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.</b>
                        
                        数据提取
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="3.1" data-path="03-数据提取/1.数据提取概述.html">
            
                
                    <a href="../03-数据提取/1.数据提取概述.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.1.</b>
                        
                        数据提取概述
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="03-数据提取/2.数据提取-jsonpath模块.html">
            
                
                    <a href="../03-数据提取/2.数据提取-jsonpath模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.2.</b>
                        
                        数据提取-jsonpath模块
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="03-数据提取/3.数据提取-lxml模块.html">
            
                
                    <a href="../03-数据提取/3.数据提取-lxml模块.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>3.3.</b>
                        
                        数据提取-lxml模块
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="4" data-path="04-selenium的使用/index.html">
            
                
                    <a href="../04-selenium的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.</b>
                        
                        selenium的使用
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="4.1" data-path="04-selenium的使用/1.selenium的介绍.html">
            
                
                    <a href="../04-selenium的使用/1.selenium的介绍.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.1.</b>
                        
                        selenium的介绍
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="04-selenium的使用/2.selenium定位获取标签对象并提取数据.html">
            
                
                    <a href="../04-selenium的使用/2.selenium定位获取标签对象并提取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.2.</b>
                        
                        selenium定位获取标签对象并提取数据
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="04-selenium的使用/3.selenium的其它使用方法.html">
            
                
                    <a href="../04-selenium的使用/3.selenium的其它使用方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>4.3.</b>
                        
                        selenium的其他使用方法
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="5" data-path="05-抓包与反爬与反爬解决方案/index.html">
            
                
                    <a href="../05-抓包与反爬与反爬解决方案/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.</b>
                        
                        抓包与反爬与反爬解决方案
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="5.1" data-path="05-抓包与反爬与反爬解决方案/1.常见的反爬手段和解决方法.html">
            
                
                    <a href="../05-抓包与反爬与反爬解决方案/1.常见的反爬手段和解决方法.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.1.</b>
                        
                        常见的反爬手段和解决方法
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.2" data-path="05-抓包与反爬与反爬解决方案/2.打码平台的使用.html">
            
                
                    <a href="../05-抓包与反爬与反爬解决方案/2.打码平台的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.2.</b>
                        
                        打码平台的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.3" data-path="05-抓包与反爬与反爬解决方案/3.chrome在爬虫中的使用.html">
            
                
                    <a href="../05-抓包与反爬与反爬解决方案/3.chrome在爬虫中的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.3.</b>
                        
                        chrome在爬虫中的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="5.4" data-path="05-抓包与反爬与反爬解决方案/4.JS的解析.html">
            
                
                    <a href="../05-抓包与反爬与反爬解决方案/4.JS的解析.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>5.4.</b>
                        
                        JS的解析
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="6" data-path="06-mongodb数据库/index.html">
            
                
                    <a href="../06-mongodb数据库/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.</b>
                        
                        mongodb数据库
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="6.1" data-path="06-mongodb数据库/1.mongodb介绍和安装.html">
            
                
                    <a href="../06-mongodb数据库/1.mongodb介绍和安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.1.</b>
                        
                        mongodb介绍和安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.2" data-path="06-mongodb数据库/2.mongodb的简单使用.html">
            
                
                    <a href="../06-mongodb数据库/2.mongodb的简单使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.2.</b>
                        
                        mongodb的简单使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.3" data-path="06-mongodb数据库/3.mongodb的增删改查.html">
            
                
                    <a href="../06-mongodb数据库/3.mongodb的增删改查.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.3.</b>
                        
                        mongodb的增删改查
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.4" data-path="06-mongodb数据库/4.mongodb的聚合操作.html">
            
                
                    <a href="../06-mongodb数据库/4.mongodb的聚合操作.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.4.</b>
                        
                        mongodb的聚合操作
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.5" data-path="06-mongodb数据库/5.mongodb的索引操作.html">
            
                
                    <a href="../06-mongodb数据库/5.mongodb的索引操作.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.5.</b>
                        
                        mongodb的索引操作
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.6" data-path="06-mongodb数据库/6.mongodb的权限管理.html">
            
                
                    <a href="../06-mongodb数据库/6.mongodb的权限管理.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.6.</b>
                        
                        mongodb的权限管理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.7" data-path="06-mongodb数据库/7.mongodb和python交互.html">
            
                
                    <a href="../06-mongodb数据库/7.mongodb和python交互.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.7.</b>
                        
                        mongodb和python交互
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="6.8" data-path="06-mongodb数据库/8.mongodb总结图.html">
            
                
                    <a href="../06-mongodb数据库/8.mongodb总结图.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>6.8.</b>
                        
                        mongdb总结
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="7" data-path="07-scrapy爬虫框架/index.html">
            
                
                    <a href="../07-scrapy爬虫框架/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.</b>
                        
                        scrapy爬虫框架
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="7.1" data-path="07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html">
            
                
                    <a href="../07-scrapy爬虫框架/1.scrapy的概念作用和工作流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.1.</b>
                        
                        scrapy的概念作用和工作流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.2" data-path="07-scrapy爬虫框架/2.scrapy的入门使用.html">
            
                
                    <a href="../07-scrapy爬虫框架/2.scrapy的入门使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.2.</b>
                        
                        scrapy的入门使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.3" data-path="07-scrapy爬虫框架/3.scrapy构造并发送请求.html">
            
                
                    <a href="../07-scrapy爬虫框架/3.scrapy构造并发送请求.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.3.</b>
                        
                        scrapy数据建模与请求
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.4" data-path="07-scrapy爬虫框架/4.scrapy模拟登陆.html">
            
                
                    <a href="../07-scrapy爬虫框架/4.scrapy模拟登陆.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.4.</b>
                        
                        scrapy模拟登陆
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.5" data-path="07-scrapy爬虫框架/5.scrapy管道的使用.html">
            
                
                    <a href="../07-scrapy爬虫框架/5.scrapy管道的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.5.</b>
                        
                        scrapy管道的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.6" data-path="07-scrapy爬虫框架/14.crawlspider类的使用.html">
            
                
                    <a href="../07-scrapy爬虫框架/14.crawlspider类的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.6.</b>
                        
                        crawlspider的使用
                    </a>
            
            
        </li>
    
        <li class="chapter active" data-level="7.7" data-path="07-scrapy爬虫框架/6.scrapy中间件的使用.html">
            
                
                    <a href="../07-scrapy爬虫框架/6.scrapy中间件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.7.</b>
                        
                        scrapy中间件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.8" data-path="07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html">
            
                
                    <a href="../07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.8.</b>
                        
                        scrapy_redis概念作用和流程
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.9" data-path="07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html">
            
                
                    <a href="../07-scrapy爬虫框架/8.scrapy_redis原理分析并实现断点续爬以及分布式爬虫.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.9.</b>
                        
                        scrapy_redis原理分析并实现断点续爬以及分布式爬虫
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.10" data-path="07-scrapy爬虫框架/9.scrapy_splash组件的使用.html">
            
                
                    <a href="../07-scrapy爬虫框架/9.scrapy_splash组件的使用.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.10.</b>
                        
                        scrapy_splash组件的使用
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.11" data-path="07-scrapy爬虫框架/10.scrapy的日志信息与配置.html">
            
                
                    <a href="../07-scrapy爬虫框架/10.scrapy的日志信息与配置.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.11.</b>
                        
                        scrapy的日志信息与配置
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.12" data-path="07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html">
            
                
                    <a href="../07-scrapy爬虫框架/11.scrapyd部署scrapy项目.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.12.</b>
                        
                        scrapyd部署scrapy项目
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.13" data-path="07-scrapy爬虫框架/12.gerapy爬虫管理.html">
            
                
                    <a href="../07-scrapy爬虫框架/12.gerapy爬虫管理.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.13.</b>
                        
                        使用gerapy进行爬虫管理
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="7.14" data-path="07-scrapy爬虫框架/13.scrapy总结图.html">
            
                
                    <a href="../07-scrapy爬虫框架/13.scrapy总结图.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>7.14.</b>
                        
                        scrapy总结图
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="8" data-path="08-appium的使用/index.html">
            
                
                    <a href="../08-appium的使用/index.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.</b>
                        
                        appium的使用
                    </a>
            
            
            <ul class="articles">
                
    
        <li class="chapter " data-level="8.1" data-path="08-appium的使用/1.appium环境安装.html">
            
                
                    <a href="../08-appium的使用/1.appium环境安装.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.1.</b>
                        
                        appium环境安装
                    </a>
            
            
        </li>
    
        <li class="chapter " data-level="8.2" data-path="08-appium的使用/2.利用appium自动控制移动设备并提取数据.html">
            
                
                    <a href="../08-appium的使用/2.利用appium自动控制移动设备并提取数据.html">
                
                        <i class="fa fa-check"></i>
                        
                            <b>8.2.</b>
                        
                        利用appium自动控制移动设备并提取数据
                    </a>
            
            
        </li>
    

            </ul>
            
        </li>
    


            
            <li class="divider"></li>
            <li>
                <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
                    Published with GitBook
                </a>
            </li>
            
        </ul>
    </nav>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header" role="navigation">
    <!-- Actions Left -->
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../" >爬虫课程概要</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1" role="main">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-">
                    
                        <h2 id="scrapy&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;">scrapy&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;</h2>
<h5 id="&#x5B66;&#x4E60;&#x76EE;&#x6807;&#xFF1A;">&#x5B66;&#x4E60;&#x76EE;&#x6807;&#xFF1A;</h5>
<ol>
<li>&#x5E94;&#x7528; scrapy&#x4E2D;&#x4F7F;&#x7528;&#x95F4;&#x4EF6;&#x4F7F;&#x7528;&#x968F;&#x673A;UA&#x7684;&#x65B9;&#x6CD5;</li>
<li>&#x5E94;&#x7528; scrapy&#x4E2D;&#x4F7F;&#x7528;&#x4EE3;&#x7406;ip&#x7684;&#x7684;&#x65B9;&#x6CD5;</li>
<li>&#x5E94;&#x7528; scrapy&#x4E0E;selenium&#x914D;&#x5408;&#x4F7F;&#x7528;</li>
</ol>
<hr>
<h3 id="1-scrapy&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x5206;&#x7C7B;&#x548C;&#x4F5C;&#x7528;">1. scrapy&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x5206;&#x7C7B;&#x548C;&#x4F5C;&#x7528;</h3>
<h5 id="11-scrapy&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x5206;&#x7C7B;">1.1 scrapy&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x5206;&#x7C7B;</h5>
<p>&#x6839;&#x636E;scrapy&#x8FD0;&#x884C;&#x6D41;&#x7A0B;&#x4E2D;&#x6240;&#x5728;&#x4F4D;&#x7F6E;&#x4E0D;&#x540C;&#x5206;&#x4E3A;&#xFF1A;</p>
<ol>
<li>&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;</li>
<li>&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;</li>
</ol>
<h5 id="12-scrapy&#x4E2D;&#x95F4;&#x7684;&#x4F5C;&#x7528;&#xFF1A;&#x9884;&#x5904;&#x7406;request&#x548C;response&#x5BF9;&#x8C61;">1.2 scrapy&#x4E2D;&#x95F4;&#x7684;&#x4F5C;&#x7528;&#xFF1A;&#x9884;&#x5904;&#x7406;request&#x548C;response&#x5BF9;&#x8C61;</h5>
<ol>
<li>&#x5BF9;header&#x4EE5;&#x53CA;cookie&#x8FDB;&#x884C;&#x66F4;&#x6362;&#x548C;&#x5904;&#x7406;</li>
<li>&#x4F7F;&#x7528;&#x4EE3;&#x7406;ip&#x7B49;</li>
<li>&#x5BF9;&#x8BF7;&#x6C42;&#x8FDB;&#x884C;&#x5B9A;&#x5236;&#x5316;&#x64CD;&#x4F5C;&#xFF0C;</li>
</ol>
<p>&#x4F46;&#x5728;scrapy&#x9ED8;&#x8BA4;&#x7684;&#x60C5;&#x51B5;&#x4E0B; &#x4E24;&#x79CD;&#x4E2D;&#x95F4;&#x4EF6;&#x90FD;&#x5728;middlewares.py&#x4E00;&#x4E2A;&#x6587;&#x4EF6;&#x4E2D;</p>
<p>&#x722C;&#x866B;&#x4E2D;&#x95F4;&#x4EF6;&#x4F7F;&#x7528;&#x65B9;&#x6CD5;&#x548C;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x76F8;&#x540C;&#xFF0C;&#x4E14;&#x529F;&#x80FD;&#x91CD;&#x590D;&#xFF0C;&#x901A;&#x5E38;&#x4F7F;&#x7528;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;</p>
<h3 id="2-&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;&#x65B9;&#x6CD5;&#xFF1A;">2. &#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;&#x65B9;&#x6CD5;&#xFF1A;</h3>
<blockquote>
<p>&#x63A5;&#x4E0B;&#x6765;&#x6211;&#x4EEC;&#x5BF9;&#x817E;&#x8BAF;&#x62DB;&#x8058;&#x722C;&#x866B;&#x8FDB;&#x884C;&#x4FEE;&#x6539;&#x5B8C;&#x5584;&#xFF0C;&#x901A;&#x8FC7;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x6765;&#x5B66;&#x4E60;&#x5982;&#x4F55;&#x4F7F;&#x7528;&#x4E2D;&#x95F4;&#x4EF6;
&#x7F16;&#x5199;&#x4E00;&#x4E2A;Downloader Middlewares&#x548C;&#x6211;&#x4EEC;&#x7F16;&#x5199;&#x4E00;&#x4E2A;pipeline&#x4E00;&#x6837;&#xFF0C;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;&#x7C7B;&#xFF0C;&#x7136;&#x540E;&#x5728;setting&#x4E2D;&#x5F00;&#x542F;</p>
</blockquote>
<p>Downloader Middlewares&#x9ED8;&#x8BA4;&#x7684;&#x65B9;&#x6CD5;&#xFF1A;</p>
<ul>
<li><p>process_request(self, request, spider)&#xFF1A;</p>
<ol>
<li>&#x5F53;&#x6BCF;&#x4E2A;request&#x901A;&#x8FC7;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x65F6;&#xFF0C;&#x8BE5;&#x65B9;&#x6CD5;&#x88AB;&#x8C03;&#x7528;&#x3002;</li>
<li>&#x8FD4;&#x56DE;None&#x503C;&#xFF1A;&#x6CA1;&#x6709;return&#x4E5F;&#x662F;&#x8FD4;&#x56DE;None&#xFF0C;&#x8BE5;request&#x5BF9;&#x8C61;&#x4F20;&#x9012;&#x7ED9;&#x4E0B;&#x8F7D;&#x5668;&#xFF0C;&#x6216;&#x901A;&#x8FC7;&#x5F15;&#x64CE;&#x4F20;&#x9012;&#x7ED9;&#x5176;&#x4ED6;&#x6743;&#x91CD;&#x4F4E;&#x7684;process_request&#x65B9;&#x6CD5;</li>
<li>&#x8FD4;&#x56DE;Response&#x5BF9;&#x8C61;&#xFF1A;&#x4E0D;&#x518D;&#x8BF7;&#x6C42;&#xFF0C;&#x628A;response&#x8FD4;&#x56DE;&#x7ED9;&#x5F15;&#x64CE;</li>
<li>&#x8FD4;&#x56DE;Request&#x5BF9;&#x8C61;&#xFF1A;&#x628A;request&#x5BF9;&#x8C61;&#x901A;&#x8FC7;&#x5F15;&#x64CE;&#x4EA4;&#x7ED9;&#x8C03;&#x5EA6;&#x5668;&#xFF0C;&#x6B64;&#x65F6;&#x5C06;&#x4E0D;&#x901A;&#x8FC7;&#x5176;&#x4ED6;&#x6743;&#x91CD;&#x4F4E;&#x7684;process_request&#x65B9;&#x6CD5;</li>
</ol>
</li>
<li><p>process_response(self, request, response, spider)&#xFF1A;</p>
<ol>
<li>&#x5F53;&#x4E0B;&#x8F7D;&#x5668;&#x5B8C;&#x6210;http&#x8BF7;&#x6C42;&#xFF0C;&#x4F20;&#x9012;&#x54CD;&#x5E94;&#x7ED9;&#x5F15;&#x64CE;&#x7684;&#x65F6;&#x5019;&#x8C03;&#x7528;</li>
<li>&#x8FD4;&#x56DE;Resposne&#xFF1A;&#x901A;&#x8FC7;&#x5F15;&#x64CE;&#x4EA4;&#x7ED9;&#x722C;&#x866B;&#x5904;&#x7406;&#x6216;&#x4EA4;&#x7ED9;&#x6743;&#x91CD;&#x66F4;&#x4F4E;&#x7684;&#x5176;&#x4ED6;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;process_response&#x65B9;&#x6CD5;</li>
<li>&#x8FD4;&#x56DE;Request&#x5BF9;&#x8C61;&#xFF1A;&#x901A;&#x8FC7;&#x5F15;&#x64CE;&#x4EA4;&#x7ED9;&#x8C03;&#x53D6;&#x5668;&#x7EE7;&#x7EED;&#x8BF7;&#x6C42;&#xFF0C;&#x6B64;&#x65F6;&#x5C06;&#x4E0D;&#x901A;&#x8FC7;&#x5176;&#x4ED6;&#x6743;&#x91CD;&#x4F4E;&#x7684;process_request&#x65B9;&#x6CD5;</li>
</ol>
</li>
<li><p>&#x5728;settings.py&#x4E2D;&#x914D;&#x7F6E;&#x5F00;&#x542F;&#x4E2D;&#x95F4;&#x4EF6;&#xFF0C;&#x6743;&#x91CD;&#x503C;&#x8D8A;&#x5C0F;&#x8D8A;&#x4F18;&#x5148;&#x6267;&#x884C;</p>
</li>
</ul>
<h3 id="3-&#x5B9A;&#x4E49;&#x5B9E;&#x73B0;&#x968F;&#x673A;useragent&#x7684;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;">3. &#x5B9A;&#x4E49;&#x5B9E;&#x73B0;&#x968F;&#x673A;User-Agent&#x7684;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;</h3>
<h4 id="31-&#x5728;middlewarespy&#x4E2D;&#x5B8C;&#x5584;&#x4EE3;&#x7801;">3.1 &#x5728;middlewares.py&#x4E2D;&#x5B8C;&#x5584;&#x4EE3;&#x7801;</h4>
<pre><code>import random
from Tencent.settings import USER_AGENTS_LIST # &#x6CE8;&#x610F;&#x5BFC;&#x5165;&#x8DEF;&#x5F84;,&#x8BF7;&#x5FFD;&#x89C6;pycharm&#x7684;&#x9519;&#x8BEF;&#x63D0;&#x793A;

class UserAgentMiddleware(object):
    def process_request(self, request, spider):
        user_agent = random.choice(USER_AGENTS_LIST)
        request.headers[&apos;User-Agent&apos;] = user_agent
        # &#x4E0D;&#x5199;return

class CheckUA:
    def process_response(self,request,response,spider):
        print(request.headers[&apos;User-Agent&apos;])
        return response # &#x4E0D;&#x80FD;&#x5C11;&#xFF01;
</code></pre><h4 id="32-&#x5728;settings&#x4E2D;&#x8BBE;&#x7F6E;&#x5F00;&#x542F;&#x81EA;&#x5B9A;&#x4E49;&#x7684;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#xFF0C;&#x8BBE;&#x7F6E;&#x65B9;&#x6CD5;&#x540C;&#x7BA1;&#x9053;">3.2 &#x5728;settings&#x4E2D;&#x8BBE;&#x7F6E;&#x5F00;&#x542F;&#x81EA;&#x5B9A;&#x4E49;&#x7684;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#xFF0C;&#x8BBE;&#x7F6E;&#x65B9;&#x6CD5;&#x540C;&#x7BA1;&#x9053;</h4>
<pre><code class="lang-python">DOWNLOADER_MIDDLEWARES = {
   <span class="hljs-string">&apos;Tencent.middlewares.UserAgentMiddleware&apos;</span>: <span class="hljs-number">543</span>, <span class="hljs-comment"># 543&#x662F;&#x6743;&#x91CD;&#x503C;</span>
   <span class="hljs-string">&apos;Tencent.middlewares.CheckUA&apos;</span>: <span class="hljs-number">600</span>, <span class="hljs-comment"># &#x5148;&#x6267;&#x884C;543&#x6743;&#x91CD;&#x7684;&#x4E2D;&#x95F4;&#x4EF6;&#xFF0C;&#x518D;&#x6267;&#x884C;600&#x7684;&#x4E2D;&#x95F4;&#x4EF6;</span>
}
</code></pre>
<h4 id="33-&#x5728;settings&#x4E2D;&#x6DFB;&#x52A0;ua&#x7684;&#x5217;&#x8868;">3.3 &#x5728;settings&#x4E2D;&#x6DFB;&#x52A0;UA&#x7684;&#x5217;&#x8868;</h4>
<pre><code>USER_AGENTS_LIST = [
    &quot;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Win64; x64; Trident/5.0; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 2.0.50727; Media Center PC 6.0)&quot;,
    &quot;Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 6.0; Trident/4.0; WOW64; Trident/4.0; SLCC2; .NET CLR 2.0.50727; .NET CLR 3.5.30729; .NET CLR 3.0.30729; .NET CLR 1.0.3705; .NET CLR 1.1.4322)&quot;,
    &quot;Mozilla/4.0 (compatible; MSIE 7.0b; Windows NT 5.2; .NET CLR 1.1.4322; .NET CLR 2.0.50727; InfoPath.2; .NET CLR 3.0.04506.30)&quot;,
    &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN) AppleWebKit/523.15 (KHTML, like Gecko, Safari/419.3) Arora/0.3 (Change: 287 c9dfb30)&quot;,
    &quot;Mozilla/5.0 (X11; U; Linux; en-US) AppleWebKit/527+ (KHTML, like Gecko, Safari/419.3) Arora/0.6&quot;,
    &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.8.1.2pre) Gecko/20070215 K-Ninja/2.1.1&quot;,
    &quot;Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9) Gecko/20080705 Firefox/3.0 Kapiko/3.0&quot;,
    &quot;Mozilla/5.0 (X11; Linux i686; U;) Gecko/20070322 Kazehakase/0.4.5&quot;
]
</code></pre><h4 id="&#x8FD0;&#x884C;&#x722C;&#x866B;&#x89C2;&#x5BDF;&#x73B0;&#x8C61;">&#x8FD0;&#x884C;&#x722C;&#x866B;&#x89C2;&#x5BDF;&#x73B0;&#x8C61;</h4>
<h3 id="4-&#x4EE3;&#x7406;ip&#x7684;&#x4F7F;&#x7528;">4. &#x4EE3;&#x7406;ip&#x7684;&#x4F7F;&#x7528;</h3>
<h4 id="41-&#x601D;&#x8DEF;&#x5206;&#x6790;">4.1 &#x601D;&#x8DEF;&#x5206;&#x6790;</h4>
<ol>
<li>&#x4EE3;&#x7406;&#x6DFB;&#x52A0;&#x7684;&#x4F4D;&#x7F6E;&#xFF1A;request.meta&#x4E2D;&#x589E;&#x52A0;<code>proxy</code>&#x5B57;&#x6BB5;</li>
<li>&#x83B7;&#x53D6;&#x4E00;&#x4E2A;&#x4EE3;&#x7406;ip&#xFF0C;&#x8D4B;&#x503C;&#x7ED9;<code>request.meta[&apos;proxy&apos;]</code><ul>
<li>&#x4EE3;&#x7406;&#x6C60;&#x4E2D;&#x968F;&#x673A;&#x9009;&#x62E9;&#x4EE3;&#x7406;ip</li>
<li>&#x4EE3;&#x7406;ip&#x7684;webapi&#x53D1;&#x9001;&#x8BF7;&#x6C42;&#x83B7;&#x53D6;&#x4E00;&#x4E2A;&#x4EE3;&#x7406;ip</li>
</ul>
</li>
</ol>
<h4 id="42-&#x5177;&#x4F53;&#x5B9E;&#x73B0;">4.2 &#x5177;&#x4F53;&#x5B9E;&#x73B0;</h4>
<p>&#x514D;&#x8D39;&#x4EE3;&#x7406;ip&#xFF1A;</p>
<pre><code>class ProxyMiddleware(object):
    def process_request(self,request,spider):
        # proxies&#x53EF;&#x4EE5;&#x5728;settings.py&#x4E2D;&#xFF0C;&#x4E5F;&#x53EF;&#x4EE5;&#x6765;&#x6E90;&#x4E8E;&#x4EE3;&#x7406;ip&#x7684;webapi
        # proxy = random.choice(proxies) 

        # &#x514D;&#x8D39;&#x7684;&#x4F1A;&#x5931;&#x6548;&#xFF0C;&#x62A5; 111 connection refused &#x4FE1;&#x606F;&#xFF01;&#x91CD;&#x627E;&#x4E00;&#x4E2A;&#x4EE3;&#x7406;ip&#x518D;&#x8BD5;
        proxy = &apos;https://1.71.188.37:3128&apos; 

        request.meta[&apos;proxy&apos;] = proxy
        return None # &#x53EF;&#x4EE5;&#x4E0D;&#x5199;return
</code></pre><p>&#x6536;&#x8D39;&#x4EE3;&#x7406;ip&#xFF1A;</p>
<pre><code># &#x4EBA;&#x6C11;&#x5E01;&#x73A9;&#x5BB6;&#x7684;&#x4EE3;&#x7801;(&#x4F7F;&#x7528;abuyun&#x63D0;&#x4F9B;&#x7684;&#x4EE3;&#x7406;ip)
import base64

# &#x4EE3;&#x7406;&#x96A7;&#x9053;&#x9A8C;&#x8BC1;&#x4FE1;&#x606F;  &#x8FD9;&#x4E2A;&#x662F;&#x5728;&#x90A3;&#x4E2A;&#x7F51;&#x7AD9;&#x4E0A;&#x7533;&#x8BF7;&#x7684;
proxyServer = &apos;http://proxy.abuyun.com:9010&apos; # &#x6536;&#x8D39;&#x7684;&#x4EE3;&#x7406;ip&#x670D;&#x52A1;&#x5668;&#x5730;&#x5740;&#xFF0C;&#x8FD9;&#x91CC;&#x662F;abuyun
proxyUser = &#x7528;&#x6237;&#x540D;
proxyPass = &#x5BC6;&#x7801;
proxyAuth = &quot;Basic &quot; + base64.b64encode(proxyUser + &quot;:&quot; + proxyPass)

class ProxyMiddleware(object):
    def process_request(self, request, spider):
        # &#x8BBE;&#x7F6E;&#x4EE3;&#x7406;
        request.meta[&quot;proxy&quot;] = proxyServer
        # &#x8BBE;&#x7F6E;&#x8BA4;&#x8BC1;
        request.headers[&quot;Proxy-Authorization&quot;] = proxyAuth
</code></pre><h4 id="43-&#x68C0;&#x6D4B;&#x4EE3;&#x7406;ip&#x662F;&#x5426;&#x53EF;&#x7528;">4.3 &#x68C0;&#x6D4B;&#x4EE3;&#x7406;ip&#x662F;&#x5426;&#x53EF;&#x7528;</h4>
<p>&#x5728;&#x4F7F;&#x7528;&#x4E86;&#x4EE3;&#x7406;ip&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#x53EF;&#x4EE5;&#x5728;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;process_response()&#x65B9;&#x6CD5;&#x4E2D;&#x5904;&#x7406;&#x4EE3;&#x7406;ip&#x7684;&#x4F7F;&#x7528;&#x60C5;&#x51B5;&#xFF0C;&#x5982;&#x679C;&#x8BE5;&#x4EE3;&#x7406;ip&#x4E0D;&#x80FD;&#x4F7F;&#x7528;&#x53EF;&#x4EE5;&#x66FF;&#x6362;&#x5176;&#x4ED6;&#x4EE3;&#x7406;ip</p>
<pre><code>class ProxyMiddleware(object):
    ......
    def process_response(self, request, response, spider):
        if response.status != &apos;200&apos;:
            request.dont_filter = True # &#x91CD;&#x65B0;&#x53D1;&#x9001;&#x7684;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x80FD;&#x591F;&#x518D;&#x6B21;&#x8FDB;&#x5165;&#x961F;&#x5217;
            return requst
</code></pre><h5 id="&#x5728;settingspy&#x4E2D;&#x5F00;&#x542F;&#x8BE5;&#x4E2D;&#x95F4;&#x4EF6;">&#x5728;settings.py&#x4E2D;&#x5F00;&#x542F;&#x8BE5;&#x4E2D;&#x95F4;&#x4EF6;</h5>
<h3 id="5-&#x5728;&#x4E2D;&#x95F4;&#x4EF6;&#x4E2D;&#x4F7F;&#x7528;selenium">5. &#x5728;&#x4E2D;&#x95F4;&#x4EF6;&#x4E2D;&#x4F7F;&#x7528;selenium</h3>
<blockquote>
<p>&#x4EE5;github&#x767B;&#x9646;&#x4E3A;&#x4F8B;</p>
</blockquote>
<h4 id="51-&#x5B8C;&#x6210;&#x722C;&#x866B;&#x4EE3;&#x7801;">5.1 &#x5B8C;&#x6210;&#x722C;&#x866B;&#x4EE3;&#x7801;</h4>
<pre><code>import scrapy

class Login4Spider(scrapy.Spider):
    name = &apos;login4&apos;
    allowed_domains = [&apos;github.com&apos;]
    start_urls = [&apos;https://github.com/1596930226&apos;] # &#x76F4;&#x63A5;&#x5BF9;&#x9A8C;&#x8BC1;&#x7684;url&#x53D1;&#x9001;&#x8BF7;&#x6C42;

    def parse(self, response):
        with open(&apos;check.html&apos;, &apos;w&apos;) as f:
            f.write(response.body.decode())
</code></pre><h4 id="52-&#x5728;middlewarespy&#x4E2D;&#x4F7F;&#x7528;selenium">5.2 &#x5728;middlewares.py&#x4E2D;&#x4F7F;&#x7528;selenium</h4>
<pre><code>import time
from selenium import webdriver


def getCookies():
    # &#x4F7F;&#x7528;selenium&#x6A21;&#x62DF;&#x767B;&#x9646;&#xFF0C;&#x83B7;&#x53D6;&#x5E76;&#x8FD4;&#x56DE;cookie
    username = input(&apos;&#x8F93;&#x5165;github&#x8D26;&#x53F7;:&apos;)
    password = input(&apos;&#x8F93;&#x5165;github&#x5BC6;&#x7801;:&apos;)
    options = webdriver.ChromeOptions()
    options.add_argument(&apos;--headless&apos;)
    options.add_argument(&apos;--disable-gpu&apos;)
    driver = webdriver.Chrome(&apos;/home/worker/Desktop/driver/chromedriver&apos;,
                              chrome_options=options)
    driver.get(&apos;https://github.com/login&apos;)
    time.sleep(1)
    driver.find_element_by_xpath(&apos;//*[@id=&quot;login_field&quot;]&apos;).send_keys(username)
    time.sleep(1)
    driver.find_element_by_xpath(&apos;//*[@id=&quot;password&quot;]&apos;).send_keys(password)
    time.sleep(1)
    driver.find_element_by_xpath(&apos;//*[@id=&quot;login&quot;]/form/div[3]/input[3]&apos;).click()
    time.sleep(2)
    cookies_dict = {cookie[&apos;name&apos;]: cookie[&apos;value&apos;] for cookie in driver.get_cookies()}
    driver.quit()
    return cookies_dict

class LoginDownloaderMiddleware(object):

    def process_request(self, request, spider):
        cookies_dict = getCookies()
        print(cookies_dict)
        request.cookies = cookies_dict # &#x5BF9;&#x8BF7;&#x6C42;&#x5BF9;&#x8C61;&#x7684;cookies&#x5C5E;&#x6027;&#x8FDB;&#x884C;&#x66FF;&#x6362;
</code></pre><h5 id="&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x4E2D;&#x8BBE;&#x7F6E;&#x5F00;&#x542F;&#x8BE5;&#x4E2D;&#x95F4;&#x4EF6;&#x540E;&#xFF0C;&#x8FD0;&#x884C;&#x722C;&#x866B;&#x53EF;&#x4EE5;&#x5728;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;&#x4E2D;&#x770B;&#x5230;selenium&#x76F8;&#x5173;&#x5185;&#x5BB9;">&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#x4E2D;&#x8BBE;&#x7F6E;&#x5F00;&#x542F;&#x8BE5;&#x4E2D;&#x95F4;&#x4EF6;&#x540E;&#xFF0C;&#x8FD0;&#x884C;&#x722C;&#x866B;&#x53EF;&#x4EE5;&#x5728;&#x65E5;&#x5FD7;&#x4FE1;&#x606F;&#x4E2D;&#x770B;&#x5230;selenium&#x76F8;&#x5173;&#x5185;&#x5BB9;</h5>
<hr>
<h2 id="&#x5C0F;&#x7ED3;">&#x5C0F;&#x7ED3;</h2>
<p>&#x4E2D;&#x95F4;&#x4EF6;&#x7684;&#x4F7F;&#x7528;&#xFF1A;</p>
<ol>
<li><p>&#x5B8C;&#x5584;&#x4E2D;&#x95F4;&#x4EF6;&#x4EE3;&#x7801;&#xFF1A;</p>
<ul>
<li><p>process_request(self, request, spider)&#xFF1A;</p>
<ol>
<li>&#x5F53;&#x6BCF;&#x4E2A;request&#x901A;&#x8FC7;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x65F6;&#xFF0C;&#x8BE5;&#x65B9;&#x6CD5;&#x88AB;&#x8C03;&#x7528;&#x3002;</li>
<li>&#x8FD4;&#x56DE;None&#x503C;&#xFF1A;&#x6CA1;&#x6709;return&#x4E5F;&#x662F;&#x8FD4;&#x56DE;None&#xFF0C;&#x8BE5;request&#x5BF9;&#x8C61;&#x4F20;&#x9012;&#x7ED9;&#x4E0B;&#x8F7D;&#x5668;&#xFF0C;&#x6216;&#x901A;&#x8FC7;&#x5F15;&#x64CE;&#x4F20;&#x9012;&#x7ED9;&#x5176;&#x4ED6;&#x6743;&#x91CD;&#x4F4E;&#x7684;process_request&#x65B9;&#x6CD5;</li>
<li>&#x8FD4;&#x56DE;Response&#x5BF9;&#x8C61;&#xFF1A;&#x4E0D;&#x518D;&#x8BF7;&#x6C42;&#xFF0C;&#x628A;response&#x8FD4;&#x56DE;&#x7ED9;&#x5F15;&#x64CE;</li>
<li>&#x8FD4;&#x56DE;Request&#x5BF9;&#x8C61;&#xFF1A;&#x628A;request&#x5BF9;&#x8C61;&#x901A;&#x8FC7;&#x5F15;&#x64CE;&#x4EA4;&#x7ED9;&#x8C03;&#x5EA6;&#x5668;&#xFF0C;&#x6B64;&#x65F6;&#x5C06;&#x4E0D;&#x901A;&#x8FC7;&#x5176;&#x4ED6;&#x6743;&#x91CD;&#x4F4E;&#x7684;process_request&#x65B9;&#x6CD5;</li>
</ol>
</li>
<li><p>process_response(self, request, response, spider)&#xFF1A;</p>
<ol>
<li>&#x5F53;&#x4E0B;&#x8F7D;&#x5668;&#x5B8C;&#x6210;http&#x8BF7;&#x6C42;&#xFF0C;&#x4F20;&#x9012;&#x54CD;&#x5E94;&#x7ED9;&#x5F15;&#x64CE;&#x7684;&#x65F6;&#x5019;&#x8C03;&#x7528;</li>
<li>&#x8FD4;&#x56DE;Resposne&#xFF1A;&#x901A;&#x8FC7;&#x5F15;&#x64CE;&#x4EA4;&#x7ED9;&#x722C;&#x866B;&#x5904;&#x7406;&#x6216;&#x4EA4;&#x7ED9;&#x6743;&#x91CD;&#x66F4;&#x4F4E;&#x7684;&#x5176;&#x4ED6;&#x4E0B;&#x8F7D;&#x4E2D;&#x95F4;&#x4EF6;&#x7684;process_response&#x65B9;&#x6CD5;</li>
<li>&#x8FD4;&#x56DE;Request&#x5BF9;&#x8C61;&#xFF1A;&#x901A;&#x8FC7;&#x5F15;&#x64CE;&#x4EA4;&#x7ED9;&#x8C03;&#x53D6;&#x5668;&#x7EE7;&#x7EED;&#x8BF7;&#x6C42;&#xFF0C;&#x6B64;&#x65F6;&#x5C06;&#x4E0D;&#x901A;&#x8FC7;&#x5176;&#x4ED6;&#x6743;&#x91CD;&#x4F4E;&#x7684;process_request&#x65B9;&#x6CD5;</li>
</ol>
</li>
</ul>
</li>
<li><p>&#x9700;&#x8981;&#x5728;settings.py&#x4E2D;&#x5F00;&#x542F;&#x4E2D;&#x95F4;&#x4EF6;
DOWNLOADER_MIDDLEWARES = {
&apos;myspider.middlewares.UserAgentMiddleware&apos;: 543,
}</p>
</li>
</ol>
<hr>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../07-scrapy爬虫框架/14.crawlspider类的使用.html" class="navigation navigation-prev " aria-label="Previous page: crawlspider的使用"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../07-scrapy爬虫框架/7.scrapy_redis概念作用和流程.html" class="navigation navigation-next " aria-label="Next page: scrapy_redis概念作用和流程"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../gitbook/app.js"></script>

    
    <script src="../gitbook/plugins/gitbook-plugin-search/lunr.min.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-search/search.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-sharing/buttons.js"></script>
    

    
    <script src="../gitbook/plugins/gitbook-plugin-fontsettings/buttons.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"highlight":{},"search":{"maxIndexSize":1000000},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
